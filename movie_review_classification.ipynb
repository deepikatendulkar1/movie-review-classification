{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKTG1p4_XDU9",
        "outputId": "d69b5d21-ed67-487f-8cf8-8c7cf6581fe4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from bs4 import BeautifulSoup\n",
        "import re\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_validation(A, b):\n",
        "    A = np.array(A)\n",
        "    b = np.array(b)\n",
        "    k = 5\n",
        "    fold_size = len(A) // k\n",
        "    accu= []\n",
        "    for i in range(k):\n",
        "        start = i * fold_size\n",
        "        end = (i + 1) * fold_size if i < k - 1 else len(A)\n",
        "        A_train = np.concatenate([A[:start], A[end:]])\n",
        "        b_train = np.concatenate([b[:start], b[end:]])\n",
        "        A_val = A[start:end]\n",
        "        b_val = b[start:end]\n",
        "        vector = TfidfVectorizer(norm='l2', min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, ngram_range=(1, 2), max_features=9000)\n",
        "        train_vector = vector.fit_transform(A_train)\n",
        "        test_vector = vector.transform(A_val)\n",
        "        cosine_ = cosine_similarity(test_vector, train_vector)\n",
        "        result = Knn(cosine_, 500)\n",
        "        accuracy = sum(1 for pred, true in zip(result, b_val) if pred == true) / len(b_val)\n",
        "        accu.append(accuracy)\n",
        "    return np.mean(accuracy)\n"
      ],
      "metadata": {
        "id": "zw4cixY25QT9"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def Knn(Sm, Knn):\n",
        "    nb = []\n",
        "    for row in Sm:\n",
        "        nindices = np.argsort(-row)[:Knn]\n",
        "        lables = [trainl[idx] for idx in nindices]\n",
        "        pos_ = sum(1 for label in lables if label == \"+1\")\n",
        "        cn = sum(1 for label in lables if label == \"-1\")\n",
        "        n = \"+1\" if pos_ > cn else \"-1\"\n",
        "        nb.append(n)\n",
        "    return nb\n"
      ],
      "metadata": {
        "id": "EySAlP735VVO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pre(text):\n",
        "    text = BeautifulSoup(text, \"lxml\").get_text()\n",
        "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
        "    text = text.lower()\n",
        "    words = text.split()\n",
        "    stop__words = set(stopwords.words(\"english\"))\n",
        "    word__ = [word for word in words if word not in stop__words]\n",
        "    return \" \".join(word__)"
      ],
      "metadata": {
        "id": "NT2XPRLD2u2x"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OAbiH4CXGBX",
        "outputId": "6f5a3200-1743-4ec1-a70d-7abf62b4c988"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-ce04338e91fd>:2: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"lxml\").get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average accuracy: 0.841\n"
          ]
        }
      ],
      "source": [
        "\n",
        "train_data = open('/content/drive/MyDrive/Deepika/train_new.txt', \"r\")\n",
        "test_data = open('/content/drive/MyDrive/Deepika/test_new.txt', \"r\")\n",
        "train_ = train_data.readlines()\n",
        "trainl = [line[:2] for line in train_]\n",
        "train__ = [pre(line[2:]) for line in train_]\n",
        "testl = test_data.readlines()\n",
        "testr = [pre(line) for line in testl]\n",
        "accuracy = cross_validation(train__, trainl)\n",
        "TFIDF = TfidfVectorizer(norm='l2', min_df=0, use_idf=True, smooth_idf=False, sublinear_tf=True, ngram_range=(1, 2), max_features=9000)\n",
        "train_v = TFIDF.fit_transform(train__)\n",
        "test_v = TFIDF.transform(testr)\n",
        "simila = cosine_similarity(test_v, train_v)\n",
        "result = Knn(simila, 500)\n",
        "print(\"Average accuracy:\", accuracy)\n",
        "with open('/content/drive/MyDrive/Deepika/output.txt', 'w') as file:\n",
        "    for r in result:\n",
        "        file.write(r + '\\n')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}